## lab1

### 论文回顾

#### mapreduce架构

严格来讲，MapReduce是一种分布式计算模型，用于解决大于1TB数据量的大数据计算处理。著名的开源项目Hadoop和Spark在计算方面都实现的是MapReduce模型。从论文中可以看到花了不少篇幅在讲解这个模型的原理和运行过程，但同时也花了一点篇幅来讲解处理分布式系统实现中可能遇到的问题。

MapReduce的模型设计很容易进行水平横向扩展以加强系统的能力，基本分为两种任务：map和reduce，通过map任务完成程序逻辑的并发，通过reduce任务完成并发结果的归约和收集，使用这个框架的开发者的任务就是把自己的业务逻辑先分为这两种任务，然后丢给MapReduce模型去运行。设计上，执行这两种任务的worker可以运行在普通的PC机器上，不需要使用太多资源。当系统整体能力不足时，通过增加worker即可解决。

#### 性能瓶颈

那么什么更容易导致系统性能扩展的瓶颈？CPU？内存？磁盘？还是网络？在2004年这篇文章问世的时候回答还是”网络带宽“最受限，论文想方设法的减少数据在系统内的搬运与传输，而到如今数据中心的内网速度要比当时快多了，因此如今更可能的答案恐怕就是磁盘了，新的架构会减少数据持久化到磁盘的次数，更多的利用内存甚至网络（这正是Spark的设计理念）

如何处理较慢的网络？参考论文3.4节减少网络带宽资源的浪费，都尽量让输入数据保存在构成集群机器的本地硬盘上，并通过使用分布式文件系统GFS进行本地磁盘的管理。尝试分配map任务到尽量靠近这个任务的输入数据库的机器上执行，这样从GFS读时大部分还是在本地磁盘读出来。中间数据传输（map到reduce）经过网络一次，但是分多个key并行执行

#### 负载均衡

某个task运行时间比较其他N-1个都长，大家都必须等其结束那就尴尬了，因此参考论文3.5节、3.6节系统设计保证task比worker数量要多，做的快的worker可以继续先执行其他task，减少等待。（框架的任务调度后来发现更值得研究）

#### 容错

参考论文3.3节重新执行那些失败的MR任务即可，因此需要保证MR任务本身是幂等且无状态的。

更特别一些，worker失效如何处理？将失败任务调配到其他worker重新执行，保证最后输出到GFS上的中间结果过程是原子性操作即可。（减少写错数据的可能）

Master失效如何处理？因为master是单点，只能人工干预，系统干脆直接终止，让用户重启重新执行这个计算

#### 其他

其实还有部分工程问题，这篇文章中并没有讨论，可能因为这些更偏重工程实践，比如：task任务的状态如何监控、数据如何移动、worker故障后如何恢复等。

### 实现思路

> lec1中讲到，mapreduce隐藏的细节，我们需要实现下面的这些：
>
> - 将应用程序代码发送到服务器
> - 跟踪哪些任务已完成
> - 将中间数据从 Maps“移到”到 Reduces
> - 平衡服务器负载
> - 从失败中恢复

#### coordinator

在lab1中，coordinator类似于论文中提到的master，是集群的管理者，负责分配job的task给worker进程。

task分两种：

- 一种是map任务，负责将给定分区文件的数据处理成中间结果，然后将中间结果输出到本地磁盘。输出时，就进行分区。（分区映射函数`hash(key) mod R`）

- 另一种是reduce任务，负责将中间结果收集合并，输出到文件里。

  一般来说，lab1中的一个reduce任务就对应一个输出文件，在map任务输出时，就已经在map worker磁盘本地分好区了。后面reduce任务就会从所有map worker里去取自己分区的中间结果集。

**coordinator管理过程**

1. 首先将map任务分配给worker，直到所有map任务完成为止
2. 所有map任务完成后，coordinator才开始分发reduce任务

**coordinator的数据结构**

- 我们需要记录分配的task状态

  - 空闲：当前task还没开始做。

    如果是中间结果集，指的是reduce任务还没开始，但是map任务已经完成了，等待分配给reduce worker；

    如果是最初的没有进入map的task，map任务空闲，等待分配给map worker；

  - 工作中：当前任务正在执行，可能是map或reduce

  - 完成：当前任务已经完成。

    如果当前任务是map任务完成，则产生中间结果，同时通知coordinator，map worker已经完成，coordinator等待所有map任务执行完毕时，就开始分发reduce任务；

    如果当前任务是reduce任务完成，则结束当前task。

```go

```

